from level2_statistical_utils import filter_data, pick_populations_v2_1, plot_spectrohistogram_and_ks, plot_population_summary, plot_spectrohistogram_and_score, plot_ks_comparison
import pickle
import copy
from typing import Callable, Dict, Optional, Union, Tuple
from collections.abc import Iterable
import numpy as np
import scipy
import os
import datetime

#TODO: Maybe add autogenerated latex table for a collection of scores

def filter_EOFAwave_stairsteps(ewave_array, mode='raw', axis = 1):
    """
    Returns a boolean array with the same length as ewave_array. Is True if the data should be removed. 
    Assumes 'ewave_array' has two dimensions, and axis indicates the frequency dimension of length 132.
    """
    assert mode in ['raw', 'log10', 'log'], AssertionError("Invalid mode for EofAWave fiter, must be 'raw', 'log10' or 'log'")

    frequency_inds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 19, 22, 23, 30, 31, 32, 35, 39, 46, 47, 48, 55, 56, 59, 62, 63, 64, 67, 70, 71, 72, 75, 78, 79, 80, 87, 91, 94, 95, 96, 99, 102, 103, 104, 107, 108, 110, 111, 114, 116, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130]
    raw_cutoffs = [22026.465794806718, 391897.4675028103, 76592.58141045694, 49757.635706215166, 64659.86406584494, 24752.84191709699, 32421.19070615171, 111802.12859612636, 120203.32406487282, 73733.88313126704, 206033.7726581579, 1145100.2062521658, 209527.46718933282, 1918932.8400038253, 10610036.910002455, 1936418.3437513441, 431602.2871898265, 219117.45797093547, 1209761.6850012152, 2010198.2175019612, 11065934.880003346, 2009078.2800029805, 136710.81703325972, 446844.1725018912, 227811.35953495247, 1254671.5500016112, 228786.2310959199, 232427.5129714612, 42309.71121289792, 50370.22933753614, 2099147.985002454, 11555511.660001969, 2098804.207502173, 39529.884026235035, 26036.582345637376, 143296.15781604825, 26084.839044941033, 31930.363653860823, 85431.60914170039, 469960.67250181653, 85401.24398588268, 97748.3692993586, 22011.3196899502, 241401.86297044903, 1328137.7175026913, 241386.67265873688, 18733.333009567556, 12756.984437475256, 71122.11820473181, 12991.982697300955, 16123.996583944876, 67148.12672260692, 12297.651419878579, 3341210.4000032456, 34433.90156539194, 97214.11734736961, 211906.40625275852, 32715.33504171259, 11928.025637710296, 2531.804636353306, 38520.20777617559, 2277.7200244677497, 7570.202258382313, 1703419.8637528059, 5771.399328606391, 21561.96603740884]
    log10_cutoffs = [4.342944819032518, 5.593172457014442, 4.88418670685809, 4.696859736149427, 4.810634787261069, 4.39362506824165, 4.510828960778236, 5.04845007214389, 5.07991647767563, 4.867667106249145, 5.31393841491719, 6.058843492892645, 5.321240963182235, 6.283059775295063, 7.0257168947196735, 6.286999188073506, 5.635083737473544, 5.340676980930829, 6.082699825620125, 6.303238883551307, 7.043988110181547, 6.302996858555627, 5.135802878810677, 5.6501560984757715, 5.357575375846445, 6.098530050366024, 5.359429884023966, 5.366287535183264, 4.626440061042169, 4.702173928221216, 6.322043056402556, 7.062789180121992, 6.321971926163401, 4.5969255402007985, 4.415583976599624, 5.156234545863786, 4.416388161276542, 4.504203864733173, 4.931618586566398, 5.672061516595154, 4.931464196827993, 4.990109520950794, 4.34264608148482, 5.382740617354802, 6.12324311031096, 5.382713288335696, 4.272615053343543, 4.105748025721965, 4.852004682592747, 4.11367543350488, 4.207472697470715, 4.827033901362397, 4.0898221786932805, 6.523903824540654, 4.536986233634749, 4.987729337363155, 5.326144086291574, 4.5147513723195996, 4.076568563904374, 3.403430190829072, 4.585688621022673, 3.357500339891719, 3.879107483004156, 6.231321707291287, 3.7612811245963633, 4.333688357640389]
    log_cutoffs = [10, 12.878755522066333, 11.246255502611115, 10.814919212341616, 11.07689594898592, 10.116695586338171, 10.386567522133788, 11.624485878843235, 11.696939955150723, 11.208217716506745, 12.235795379276729, 13.95100270751858, 12.252610118052692, 14.467279776984931, 16.177310989377936, 14.476350610123724, 12.975259811679754, 12.297363202787773, 14.00593394363038, 14.51374389084567, 16.21938201773133, 14.513186607698486, 11.825623149305368, 13.009965205439709, 12.336273195015997, 14.042384383149033, 12.34054335790039, 12.356333683232744, 10.652771918186161, 10.827155591787424, 14.557042098939041, 16.262673081108538, 14.556878315510701, 10.58481222246996, 10.167257841381662, 11.872668801286876, 10.169109545030748, 10.371312674740773, 11.355471441760153, 13.060404294657198, 11.355115946249992, 11.490151795348957, 9.999312131375953, 12.394218304974734, 14.099288306580512, 12.394155377582734, 9.838059729930801, 9.45383419961713, 11.172153653275366, 9.472087730604155, 9.688063912375515, 11.114656304653947, 9.41716358165558, 15.021843694514152, 10.446796868686572, 11.48467122010147, 12.263899976233372, 10.39559920847752, 9.386646005814354, 7.836687622448901, 10.558938259879227, 7.730930232357114, 8.931975064487023, 14.348148472859124, 8.660669848055466, 9.978686209984607]

    
    if axis == 0:
        local_e_a = ewave_array.T
    else:
        local_e_a = ewave_array
    bool_filter = np.zeros(len(local_e_a), dtype = bool)
    mode_cutoff = {'raw': raw_cutoffs, 'log10': log10_cutoffs, 'log': log_cutoffs}
    for i, f_i in enumerate(frequency_inds):
        bool_filter = bool_filter | (local_e_a[:, f_i] > mode_cutoff[mode][i])
    return bool_filter

def merge_two_dicts(x, y):
    z = x.copy()   # start with keys and values of x
    z.update(y)    # modifies z with keys and values of y
    return z

def perform_statistical_experiment(
        dataset: Dict[str, np.ndarray], 
        score_extractor: Callable[Dict[str, np.ndarray], np.ndarray],
        score_str_repr: str,
        quantile_score_cutoffs: Optional[Tuple[float, float]] = [.2, .8],
        save_directory: str = './statistical_experiments/',
        hist_fig_name: Optional[str] = None,
        ks_fig_name: Optional[str] = None,
        spec_fig_name: Optional[str] = None,
        hist_fig_log_axis = False,
        unleash_monkeys = False,
        pop_hist_ymax = None,
        data_filter_kwargs={},
        population_picker_kwargs={},
        ks_test_kwargs={},
        plot_SK_kwargs={},
        show_plots=False
    ):
    '''
    This function generates plots and statistics from the supplied scoring function. The scoring function should attempt to give low scores
    to times when arase records higher measurements (Typically E of AWave power), and higher scores to instances when Arase records lower
    measurements, as a function of generator characteristics. The analysis generated by this function caractarizes the effectiveness of the score
    at predicting Arase measurements from generator features such as relative positions.
    
    INPUTS: 
        dataset: A dataset of the form extracted by the `load_data_for_stats` function.
        score_extractor: A function to extract the score from the dataset. Cannot use Arase measurements to estimate score. Should return an np.nan score for invalid instances.
        score_str_repr: The name of the string to be used in the generated plots.
        quantile_score_cutoffs: The quantiles score cutoffs [a, b] for which the experiment popluation can be no larger than `a`-th quantile, and the control population can be no smaller than the `b`-th quantile. Explicit score cutoffsc can be provided as part of the 'population_picker_kwargs'.
        save_directory: The path to the directory where figures should be saved.
        hist_fig_name: The filename of the saved population histogram summary figure (should end in save format, such as .png, or the likes)
        ks_fig_name: The filename for the saved statistics and ks test figure (should end in save format, such as .png, or the likes).
        data_filter_kwargs: kwargs to be passed to the `filter_Data` function
        population_picker_kwargs: kwargs to be passed to the `pick_populations...` function
        ks_test_kwargs: kwargs to be passed to scipy's ks_test_function
        plot_SK_kwargs: kwargs to be passed to the the `plot_spectrohistogram_and_ks` function
        show_plots: If True, plots are shown with `plt.show()` else, they are only saved in the specified directory.
    
    OUTPUTS:
        results: dictionary containing the following experiment results...
        results[...]: an undocumented result...
        
    '''
    results = {}
    dataset = copy.deepcopy(dataset)
    score = score_extractor(dataset)
    
    # Get filtered data (discard nans and apply standard filtering)
    default_data_filter_kwargs = {
        'acceptable_flags': [5]
    }
    data_filter_kwargs = merge_two_dicts(default_data_filter_kwargs, data_filter_kwargs)
    filtered_data, filtered_score = filter_data(dataset, score, **data_filter_kwargs)

    # Get the experiment and control population indices from the filtered dataset
    default_population_picker_kwargs = {
        'max_population_sizes': 1500,
        'lvs': ['LT', 'lon', 'lat'],
        'num': [20, 50, 10],
    }
    if quantile_score_cutoffs is not None:
        score_cutoffs = np.nanquantile(filtered_score, quantile_score_cutoffs)
        default_population_picker_kwargs['score_experiment_cutoff'] = score_cutoffs[0]
        default_population_picker_kwargs['score_control_cutoff'] = score_cutoffs[1]
    population_picker_kwargs = merge_two_dicts(default_population_picker_kwargs, population_picker_kwargs)
    n_lv_bins = []
    if isinstance(population_picker_kwargs['num'], int):
        n_lv_bins = [population_picker_kwargs['num']] * len(population_picker_kwargs['lvs'])
    elif isinstance(population_picker_kwargs['num'], list):
        if isinstance(population_picker_kwargs['num'][0], int):
            n_lv_bins = population_picker_kwargs['num']
        elif isinstance(population_picker_kwargs['num'][0] is Iterable):
            n_lv_bins = [len(population_picker_kwargs['num'][i]) for i in range(len(population_picker_kwargs['num']))]
    lv_str_reprs = [f"{lv}: {nbin}" for lv, nbin in zip(population_picker_kwargs['lvs'], n_lv_bins)]
    lv_str_repr = "; ".join(lv_str_reprs)

    lv_fname_reprs = [f"{lv}_{nbin}" for lv, nbin in zip(population_picker_kwargs['lvs'], n_lv_bins)]
    lv_fname_repr = "_".join(lv_fname_reprs)
    fname_addtl = f"SCRFN_{score_str_repr.replace(' ', '')}_LVBINS_{lv_fname_repr}"

    experiment, control = pick_populations_v2_1(filtered_data, filtered_score, **population_picker_kwargs)

    # retrieve statistics and plot results
    default_ks_test_kwargs = {
        # 'nan_policy': 'omit',
        'alternative': 'greater',
        # 'alternative': 'two-sided',
    }
    ks_test_kwargs = merge_two_dicts(default_ks_test_kwargs, ks_test_kwargs)
    ks_test_results = scipy.stats.ks_2samp(filtered_data['spectra'][control], filtered_data['spectra'][experiment], axis=0, **ks_test_kwargs)
    if ks_fig_name is None:
        ks_fig_name = 'StatPlots_' +fname_addtl + "_DTGEN_" + datetime.datetime.now().strftime("%Y_%m_%d_%H%M%S") + ".png"
    ks_save_path = os.path.join(save_directory, ks_fig_name)
    ks_fig_sup_title = f"Score: {score_str_repr}, Latent Variable Number Of Bins: {lv_str_repr}"

    plot_spectrohistogram_and_ks(experiment, control, filtered_data['spectra'], filtered_data['f'], ks_fig_sup_title, ks_test_results.pvalue, **plot_SK_kwargs, save=ks_save_path, show_plot=show_plots)

    # plot population distribtions
    if hist_fig_name is None:
        hist_fig_name = 'HistPlots_' + fname_addtl + "_DTGEN_" + datetime.datetime.now().strftime("%Y_%m_%d_%H%M%S") + ".png"
    hist_save_path = os.path.join(save_directory, hist_fig_name)
    plot_population_summary(filtered_data, filtered_score, experiment, control, population_picker_kwargs['lvs'], score_str_repr, hist_fig_log_axis, hist_save_path, show_plot=show_plots)


    # plot
    if spec_fig_name is None:
        spec_fig_name = 'SpecPlots_' +fname_addtl + "_DTGEN_" + datetime.datetime.now().strftime("%Y_%m_%d_%H%M%S") + ".png"
    spec_fig_path = os.path.join(save_directory, spec_fig_name)
    plot_spectrohistogram_and_score(experiment, control, filtered_data['spectra'], filtered_data['f'], score_str_repr, filtered_score, population_picker_kwargs['score_experiment_cutoff'], population_picker_kwargs['score_control_cutoff'], save = spec_fig_path, pop_hist_ymax=pop_hist_ymax)
    min_pvalue_index = np.argmin(ks_test_results.pvalue)
    min_pvalue = ks_test_results.pvalue[min_pvalue_index]
    min_pvalue_frequency = filtered_data['f'][min_pvalue_index]

    results['ks_test_pvalue'] = ks_test_results.pvalue
    results['ks_test_statistic'] = ks_test_results.statistic
    results['ks_test_min_pvalue'] = min_pvalue
    results['ks_test_frequency_of_min_pvalue'] = min_pvalue_frequency
    results['experiment_size'] = experiment.sum()
    results['control_size'] = experiment.sum()
    results['score_experiment_cutoff'] = population_picker_kwargs['score_experiment_cutoff']
    results['score_control_cutoff'] = population_picker_kwargs['score_control_cutoff']
    results['data_filter_kwargs'] = data_filter_kwargs
    results['population_picker_kwargs'] = population_picker_kwargs
    results['ks_test_kwargs'] = ks_test_kwargs
    results['score_string_repr'] = score_str_repr
    results['latent_var_str_repr'] = lv_str_repr

    # Generate KS P-value curves for 100 randomly selected scores to use for comparison (unleash the monkeys!)
    if unleash_monkeys:
        n_tests = 100
        nf = len(filtered_data['f'])
        n_filtered = len(filtered_data['t'])
        monkey_p = np.empty((n_tests, nf))

        for i_test in range(n_tests):
            np.random.seed(i_test)
            score_random = np.random.uniform(low=0.0, high=1.0, size=(n_filtered,))
            # Choose s0 and s1 to have a reasonable population size
            s0_random = 0.1
            s1_random = 0.9
            population_picker_kwargs['score_experiment_cutoff'] = s0_random
            population_picker_kwargs['score_control_cutoff'] = s1_random
            experiment_random, control_random = pick_populations_v2_1(filtered_data, score_random, **population_picker_kwargs)
            ks_test_results = scipy.stats.ks_2samp(filtered_data['spectra'][control_random], filtered_data['spectra'][experiment_random], axis=0, **ks_test_kwargs)
            monkey_p[i_test,:] = ks_test_results.pvalue

        results['monkey_p'] = monkey_p 

    return results

def results_to_latex_table_row(experiment_results, n='n'):
    return (
        f"{n} & {experiment_results['score_string_repr']} & "
        f"{experiment_results['latent_var_str_repr']} & "
        f"{experiment_results['experiment_size']} & "
        f"{experiment_results['score_experiment_cutoff']:.3g} & " 
        f"{experiment_results['control_size']} & "
        f"{experiment_results['score_control_cutoff']:.3g} & " 
        f"{experiment_results['ks_test_min_pvalue']:.3g} \\\\ \\\cline{{1-2}} \\\cline{{4-8\}}"
    )


def dx_score(dataset):
    score = np.nanmin(dataset['dx'], axis=1)
    score[np.isnan(score)] = 500 + 1e-7
    return score

def b_perp_score(dataset):
    score = np.nanmin(dataset['B_perp'], axis=1)
    score[np.isnan(score)] = 500 + 1e-7
    return score

def wake_angle_score(dataset):
    score = np.nanmin(dataset["mach_angle"], axis=1)
    score[np.isnan(score)] = 180 + 1e-7
    return score

def rcs_nan_filter(dataset):
    dx_non_nan = ~np.isnan(dataset["dx"])
    rcs_non_nan = ~np.isnan(dataset["RCS"]) & dx_non_nan

    nan_filter = np.sum(rcs_non_nan, axis=1) - np.sum(dx_non_nan, axis=1) < 0
    return nan_filter

def power_score_1(dataset, inversion_method="divide"):
    nan_filter = rcs_nan_filter(dataset)
    generator_power = dataset["RCS"] / (dataset['dx'] ** 2)
    total_power = np.nansum(generator_power, axis=1)
    total_power[nan_filter] = np.nan
    total_power[total_power == 0] = np.nan
    
    if inversion_method == "negate":
        return - total_power
    elif inversion_method == "divide":
        return 1 / total_power

def power_score_2(dataset, inversion_method="negate", lambda_0 = 100):
    nan_filter = rcs_nan_filter(dataset)
    generator_power = dataset["RCS"] * np.exp(- dataset['dx'] / lambda_0)
    total_power = np.nansum(generator_power, axis=1)
    total_power[nan_filter] = np.nan
    total_power[total_power == 0] = np.nan
    
    if inversion_method == "negate":
        return - total_power
    elif inversion_method == "divide":
        return 1 / total_power

if __name__ == "__main__":
    EorB = 'E'
    meas = 'wave'
    filename = f'./data_{EorB}_OFA{meas}.pickle'

    with open(filename, 'rb') as f:
        data = pickle.load(f)

    file_indices = np.zeros_like(data['filename'], dtype=int)
    for i, fn in enumerate(np.unique(data['filename'])):
        i_fn_inds = data['filename'] == fn
        file_indices[i_fn_inds] = i
    data['file_index'] = file_indices

    is_not_stairstep_obs = ~filter_EOFAwave_stairsteps(data['spectra'])
    good_spectra_obs = np.all(~np.isnan(data['spectra']), axis=1)
    lv_non_nans = np.ones_like(good_spectra_obs, dtype=bool)
    for lv in ['LT', 'lon', 'lat', 'file_index']:
        lv_non_nans = lv_non_nans & ~np.isnan(data[lv])

    data_filter_kwargs = {
        "other_filter": is_not_stairstep_obs & good_spectra_obs & lv_non_nans
    }

    LV_NAMES_1 = ["alt", "file_index"]
    LV_BINS_1 = [30, 289]

    LV_NAMES_2 = ["lat", "lon", "LT"]
    LV_BINS_2 = [10, 50, 20]

    LV_NAMES_3 = ["lat", "lon", "LT", "file_index"]
    LV_BINS_3 = [10, 50, 20, 20]


    QUANTILE_CUTOFFS = [.2, .8]

    latex_table_rows = []

    #####################################
    ### FIRST SET OF LATENT VARIABLES ###
    #####################################
    results = perform_statistical_experiment(
        data,
        dx_score,
        'nanmin(dx)', 
        unleash_monkeys=True,
        pop_hist_ymax=700,
        population_picker_kwargs={
            'score_experiment_cutoff': 150,
            'score_control_cutoff': 300,
            'lvs': LV_NAMES_1,
            'num': LV_BINS_1
        },
        data_filter_kwargs=data_filter_kwargs
    )
    lr = results_to_latex_table_row(results, n=f"{len(latex_table_rows) + 1}")
    latex_table_rows.append(lr)
    # print(results)
    p0 = results['ks_test_pvalue']
    monkey_p = results['monkey_p']

    results = perform_statistical_experiment(
        data,
        b_perp_score,
        'nanmin(B_perp)',
        pop_hist_ymax=700, 
        population_picker_kwargs={
            'score_experiment_cutoff': 100,
            'score_control_cutoff': 250,
            'lvs': LV_NAMES_1,
            'num': LV_BINS_1
        },
        hist_fig_log_axis=False,
        data_filter_kwargs=data_filter_kwargs
    )
    lr = results_to_latex_table_row(results, n=f"{len(latex_table_rows) + 1}")
    latex_table_rows.append(lr)
    p1 = results['ks_test_pvalue']
    

    results = perform_statistical_experiment(
        data,
        wake_angle_score,
        'nanmin(mach_angle)',
        pop_hist_ymax=400, 
        population_picker_kwargs={
            'score_experiment_cutoff': 40,
            'score_control_cutoff': 90,
            'lvs': LV_NAMES_1,
            'num': LV_BINS_1
        },
        data_filter_kwargs=data_filter_kwargs
    )
    lr = results_to_latex_table_row(results, n=f"{len(latex_table_rows) + 1}")
    latex_table_rows.append(lr)
    p2 = results['ks_test_pvalue']
    

    results = perform_statistical_experiment(
        data,
        lambda x: power_score_1(x, inversion_method="divide"),
        'PT1^-1', 
        quantile_score_cutoffs=QUANTILE_CUTOFFS,
        population_picker_kwargs={
            'lvs': LV_NAMES_1,
            'num': LV_BINS_1
        },
        hist_fig_log_axis=True,
        data_filter_kwargs=data_filter_kwargs
    )
    lr = results_to_latex_table_row(results, n=f"{len(latex_table_rows) + 1}")
    latex_table_rows.append(lr)
    

    results = perform_statistical_experiment(
        data,
        lambda x: power_score_2(x, inversion_method="divide"),
        'PT2^-1', 
        quantile_score_cutoffs=QUANTILE_CUTOFFS,
        population_picker_kwargs={
            'lvs': LV_NAMES_1,
            'num': LV_BINS_1
        },
        hist_fig_log_axis=True,
        data_filter_kwargs=data_filter_kwargs
    )
    lr = results_to_latex_table_row(results, n=f"{len(latex_table_rows) + 1}")
    latex_table_rows.append(lr)
    

    ######################################
    ### SECOND SET OF LATENT VARIABLES ###
    ######################################
    results = perform_statistical_experiment(
        data,
        dx_score,
        'nanmin(dx)', 
        population_picker_kwargs={
            'score_experiment_cutoff': 150,
            'score_control_cutoff': 300,
            'lvs': LV_NAMES_2,
            'num': LV_BINS_2
        },
        data_filter_kwargs=data_filter_kwargs
    )
    lr = results_to_latex_table_row(results, n=f"{len(latex_table_rows) + 1}")
    latex_table_rows.append(lr)


    results = perform_statistical_experiment(
        data,
        b_perp_score,
        'nanmin(B_perp)', 
        population_picker_kwargs={
            'score_experiment_cutoff': 100,
            'score_control_cutoff': 250,
            'lvs': LV_NAMES_2,
            'num': LV_BINS_2
        },
        hist_fig_log_axis=False,
        data_filter_kwargs=data_filter_kwargs
    )
    lr = results_to_latex_table_row(results, n=f"{len(latex_table_rows) + 1}")
    latex_table_rows.append(lr)
    

    results = perform_statistical_experiment(
        data,
        wake_angle_score,
        'nanmin(mach_angle)', 
        population_picker_kwargs={
            'score_experiment_cutoff': 40,
            'score_control_cutoff': 90,
            'lvs': LV_NAMES_2,
            'num': LV_BINS_2
        },
        data_filter_kwargs=data_filter_kwargs
    )
    lr = results_to_latex_table_row(results, n=f"{len(latex_table_rows) + 1}")
    latex_table_rows.append(lr)
    

    results = perform_statistical_experiment(
        data,
        lambda x: power_score_1(x, inversion_method="divide"),
        'PT1^-1', 
        quantile_score_cutoffs=QUANTILE_CUTOFFS,
        population_picker_kwargs={
            'lvs': LV_NAMES_2,
            'num': LV_BINS_2
        },
        hist_fig_log_axis=True,
        data_filter_kwargs=data_filter_kwargs
    )
    lr = results_to_latex_table_row(results, n=f"{len(latex_table_rows) + 1}")
    latex_table_rows.append(lr)
    

    results = perform_statistical_experiment(
        data,
        lambda x: power_score_2(x, inversion_method="divide"),
        'PT2^-1', 
        quantile_score_cutoffs=QUANTILE_CUTOFFS,
        population_picker_kwargs={
            'lvs': LV_NAMES_2,
            'num': LV_BINS_2
        },
        hist_fig_log_axis=True,
        data_filter_kwargs=data_filter_kwargs
    )
    lr = results_to_latex_table_row(results, n=f"{len(latex_table_rows) + 1}")
    latex_table_rows.append(lr)

    #####################################
    ### THIRD SET OF LATENT VARIABLES ###
    #####################################
    results = perform_statistical_experiment(
        data,
        dx_score,
        'nanmin(dx)', 
        population_picker_kwargs={
            'score_experiment_cutoff': 150,
            'score_control_cutoff': 300,
            'lvs': LV_NAMES_3,
            'num': LV_BINS_3
        },
        data_filter_kwargs=data_filter_kwargs
    )
    lr = results_to_latex_table_row(results, n=f"{len(latex_table_rows) + 1}")
    latex_table_rows.append(lr)


    results = perform_statistical_experiment(
        data,
        b_perp_score,
        'nanmin(B_perp)', 
        population_picker_kwargs={
            'score_experiment_cutoff': 100,
            'score_control_cutoff': 250,
            'lvs': LV_NAMES_3,
            'num': LV_BINS_3
        },
        hist_fig_log_axis=False,
        data_filter_kwargs=data_filter_kwargs
    )
    lr = results_to_latex_table_row(results, n=f"{len(latex_table_rows) + 1}")
    latex_table_rows.append(lr)
    

    results = perform_statistical_experiment(
        data,
        wake_angle_score,
        'nanmin(mach_angle)', 
        population_picker_kwargs={
            'score_experiment_cutoff': 40,
            'score_control_cutoff': 90,
            'lvs': LV_NAMES_3,
            'num': LV_BINS_3
        },
        data_filter_kwargs=data_filter_kwargs
    )
    lr = results_to_latex_table_row(results, n=f"{len(latex_table_rows) + 1}")
    latex_table_rows.append(lr)
    

    results = perform_statistical_experiment(
        data,
        lambda x: power_score_1(x, inversion_method="divide"),
        'PT1^-1', 
        quantile_score_cutoffs=QUANTILE_CUTOFFS,
        population_picker_kwargs={
            'lvs': LV_NAMES_3,
            'num': LV_BINS_3
        },
        hist_fig_log_axis=True,
        data_filter_kwargs=data_filter_kwargs
    )
    lr = results_to_latex_table_row(results, n=f"{len(latex_table_rows) + 1}")
    latex_table_rows.append(lr)
    

    results = perform_statistical_experiment(
        data,
        lambda x: power_score_2(x, inversion_method="divide"),
        'PT2^-1', 
        quantile_score_cutoffs=QUANTILE_CUTOFFS,
        population_picker_kwargs={
            'lvs': LV_NAMES_3,
            'num': LV_BINS_3
        },
        hist_fig_log_axis=True,
        data_filter_kwargs=data_filter_kwargs
    )
    lr = results_to_latex_table_row(results, n=f"{len(latex_table_rows) + 1}")
    latex_table_rows.append(lr)
    


    print("\n\n")
    print("Almost Full Latex Table:")
    for lr in latex_table_rows:
        print(lr)

    
    ####################################################
    ### PLOT KS TEST COMPARISON FOR FIRST THREE ROWS ###
    ####################################################
    p_values = [p0, p1, p2]
    labels = ["min(dx)", "min(B_perp)", "min(wake_angle)"]
    plot_ks_comparison(data['f'], p_values, labels, monkey_p)